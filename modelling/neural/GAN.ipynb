{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de exemplo (substitua pelos seus dados de clientes)\n",
    "data = np.random.rand(1000, 10)  # 1000 clientes, 10 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsantos/Programming/Python/DS-useful-codes/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Definir o gerador\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=100),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(data.shape[1], activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Definir o discriminador\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(512, activation='relu', input_shape=(data.shape[1],)),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compilar os modelos\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Definir a GAN\n",
    "discriminator.trainable = False\n",
    "gan_input = layers.Input(shape=(100,))\n",
    "generated_data = generator(gan_input)\n",
    "gan_output = discriminator(generated_data)\n",
    "gan = tf.keras.Model(gan_input, gan_output)\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Treinamento da GAN\n",
    "def train_gan(gan, generator, discriminator, data, epochs=10000, batch_size=128):\n",
    "    for epoch in range(epochs):\n",
    "        # Treinar o discriminador\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        generated_data = generator.predict(noise)\n",
    "        real_data = data[np.random.randint(0, data.shape[0], batch_size)]\n",
    "        combined_data = np.concatenate([real_data, generated_data])\n",
    "        labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "        d_loss = discriminator.train_on_batch(combined_data, labels)\n",
    "\n",
    "        # Treinar o gerador\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        misleading_labels = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, misleading_labels)\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar a GAN\n",
    "#train_gan(gan, generator, discriminator, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "# Gerar dados sintéticos\n",
    "noise = np.random.normal(0, 1, (1000, 100))\n",
    "synthetic_data = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4008165 , 0.5800118 , 0.54340154, ..., 0.26501888, 0.32330608,\n",
       "        0.47051   ],\n",
       "       [0.53604656, 0.5849404 , 0.5818162 , ..., 0.4545664 , 0.42251897,\n",
       "        0.4944078 ],\n",
       "       [0.4389861 , 0.6372395 , 0.45832837, ..., 0.33542344, 0.32679877,\n",
       "        0.5543906 ],\n",
       "       ...,\n",
       "       [0.46737742, 0.54867464, 0.57548684, ..., 0.36761215, 0.3397899 ,\n",
       "        0.5451847 ],\n",
       "       [0.45582876, 0.5680332 , 0.4897923 , ..., 0.43130422, 0.4025774 ,\n",
       "        0.520517  ],\n",
       "       [0.42117012, 0.5261151 , 0.42199954, ..., 0.4364507 , 0.36540106,\n",
       "        0.53169656]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
